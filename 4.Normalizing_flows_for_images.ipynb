{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan1691996/normalization_flow_basis/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.distributions.uniform import Uniform\n",
    "from torch.distributions.beta import Beta\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "import pickle\n",
    "from utils import *\n",
    "import torch.utils.data as data\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = 'shape.pkl'\n",
    "with open(FILENAME, 'rb') as f:\n",
    "    shape_data = pickle.load(f)\n",
    "training_data, testing_data = shape_data['train'], shape_data['test']\n",
    "# training_data.shape = (10479, 20, 20, 1)\n",
    "training_data = (training_data > 127.5).astype(np.uint8)\n",
    "# training_data.shape = (4491, 20, 20, 1)\n",
    "testing_data = (testing_data > 127.5).astype(np.uint8)\n",
    "\n",
    "train_loader = data.DataLoader(ShapesDataset(training_data), shuffle=True, batch_size=128)\n",
    "test_loader = data.DataLoader(ShapesDataset(testing_data), shuffle=True, batch_size=128)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoRegressiveFlow(\n",
       "  (model): Sequential(\n",
       "    (0): MaskedConv2d(1, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaskedConv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaskedConv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (7): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (8): ReLU()\n",
       "    (9): MaskedConv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (10): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (11): ReLU()\n",
       "    (12): MaskedConv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (13): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (14): ReLU()\n",
       "    (15): MaskedConv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (16): MaskedConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (17): MaskedConv2d(64, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow = AutoRegressiveFlow(1, num_layers=5, n_components=10)\n",
    "flow.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of parameters is 1013790\n",
      "Starting epoch: 1 of 20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter loc (Tensor of shape (128, 10, 1, 20, 20)) of distribution Normal(loc: torch.Size([128, 10, 1, 20, 20]), scale: torch.Size([128, 10, 1, 20, 20])) to satisfy the constraint Real(), but found invalid values:\ntensor([[[[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         ...,\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]]],\n\n\n\n        [[[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         ...,\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]]],\n\n\n\n        [[[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         ...,\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]]],\n\n\n\n        ...,\n\n\n\n        [[[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         ...,\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]]],\n\n\n\n        [[[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         ...,\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]]],\n\n\n\n        [[[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         ...,\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]]]], grad_fn=<SplitBackward0>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m flow, train_losses, test_losses\n\u001b[1;32m     14\u001b[0m target_distribution \u001b[39m=\u001b[39m Uniform(torch\u001b[39m.\u001b[39mtensor(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device),torch\u001b[39m.\u001b[39mtensor(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device))\n\u001b[0;32m---> 15\u001b[0m flow, train_losses, test_losses \u001b[39m=\u001b[39m train_and_eval(flow, \u001b[39m20\u001b[39;49m, \u001b[39m1e-3\u001b[39;49m, train_loader, test_loader, target_distribution)\n\u001b[1;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtrain losses are\u001b[39m\u001b[39m'\u001b[39m, train_losses)\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtest losses are\u001b[39m\u001b[39m'\u001b[39m, test_losses)\n",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m, in \u001b[0;36mtrain_and_eval\u001b[0;34m(flow, epochs, lr, train_loader, test_loader, target_distribution)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mStarting epoch:\u001b[39m\u001b[39m'\u001b[39m, epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mof\u001b[39m\u001b[39m'\u001b[39m, epochs)\n\u001b[0;32m----> 9\u001b[0m     train(flow, train_loader, optimizer, target_distribution)\n\u001b[1;32m     10\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(eval_loss(flow, train_loader, target_distribution))\n\u001b[1;32m     11\u001b[0m     test_losses\u001b[39m.\u001b[39mappend(eval_loss(flow, test_loader, target_distribution))\n",
      "File \u001b[0;32m~/normalization_flow_basis/utils.py:198\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, target_distribution)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m    197\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m--> 198\u001b[0m     z, log_dz_by_dx \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m    199\u001b[0m     loss \u001b[39m=\u001b[39m loss_function(target_distribution, z, log_dz_by_dx)\n\u001b[1;32m    200\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/normalization_flow_basis/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/normalization_flow_basis/utils.py:179\u001b[0m, in \u001b[0;36mAutoRegressiveFlow.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    176\u001b[0m mus, log_sigmas, weight_logits \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mchunk(out, \u001b[39m3\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m# (B, n_components, c_in, h, w)\u001b[39;00m\n\u001b[1;32m    177\u001b[0m weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(weight_logits, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 179\u001b[0m distribution \u001b[39m=\u001b[39m Normal(mus, log_sigmas\u001b[39m.\u001b[39;49mexp())\n\u001b[1;32m    181\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m) \u001b[39m# x.size() is (B, 1, c_in, h, w)\u001b[39;00m\n\u001b[1;32m    182\u001b[0m z \u001b[39m=\u001b[39m distribution\u001b[39m.\u001b[39mcdf(x) \u001b[39m# z.size() is (B, n_components, c_in, h, w)\u001b[39;00m\n",
      "File \u001b[0;32m~/normalization_flow_basis/lib/python3.10/site-packages/torch/distributions/normal.py:56\u001b[0m, in \u001b[0;36mNormal.__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     batch_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc\u001b[39m.\u001b[39msize()\n\u001b[0;32m---> 56\u001b[0m \u001b[39msuper\u001b[39;49m(Normal, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(batch_shape, validate_args\u001b[39m=\u001b[39;49mvalidate_args)\n",
      "File \u001b[0;32m~/normalization_flow_basis/lib/python3.10/site-packages/torch/distributions/distribution.py:56\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     54\u001b[0m         valid \u001b[39m=\u001b[39m constraint\u001b[39m.\u001b[39mcheck(value)\n\u001b[1;32m     55\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m valid\u001b[39m.\u001b[39mall():\n\u001b[0;32m---> 56\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     57\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected parameter \u001b[39m\u001b[39m{\u001b[39;00mparam\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(value)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m of shape \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(value\u001b[39m.\u001b[39mshape)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof distribution \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mto satisfy the constraint \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(constraint)\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut found invalid values:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     62\u001b[0m             )\n\u001b[1;32m     63\u001b[0m \u001b[39msuper\u001b[39m(Distribution, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: Expected parameter loc (Tensor of shape (128, 10, 1, 20, 20)) of distribution Normal(loc: torch.Size([128, 10, 1, 20, 20]), scale: torch.Size([128, 10, 1, 20, 20])) to satisfy the constraint Real(), but found invalid values:\ntensor([[[[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         ...,\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]]],\n\n\n\n        [[[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         ...,\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]]],\n\n\n\n        [[[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         ...,\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]]],\n\n\n\n        ...,\n\n\n\n        [[[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         ...,\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]]],\n\n\n\n        [[[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         ...,\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]]],\n\n\n\n        [[[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         ...,\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n         [[[nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           ...,\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan],\n           [nan, nan, nan,  ..., nan, nan, nan]]]]], grad_fn=<SplitBackward0>)"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "def train_and_eval(flow, epochs, lr, train_loader, test_loader, target_distribution):\n",
    "    print('no of parameters is', sum(param.numel() for param in flow.parameters()))\n",
    "    optimizer = torch.optim.Adam(flow.parameters(), lr=lr)\n",
    "    train_losses, test_losses = [], []\n",
    "    for epoch in range(epochs):\n",
    "        print('Starting epoch:', epoch+1, 'of', epochs)\n",
    "        train(flow, train_loader, optimizer, target_distribution)\n",
    "        train_losses.append(eval_loss(flow, train_loader, target_distribution))\n",
    "        test_losses.append(eval_loss(flow, test_loader, target_distribution))\n",
    "    return flow, train_losses, test_losses\n",
    "\n",
    "target_distribution = Uniform(torch.tensor(0).float().to(device),torch.tensor(1).float().to(device))\n",
    "flow, train_losses, test_losses = train_and_eval(flow, 20, 1e-3, train_loader, test_loader, target_distribution)\n",
    "print('train losses are', train_losses)\n",
    "print('test losses are', test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normalization_flow_basis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7bd2415e548bb5113413fa4736da46f6b3b26cc792666494ea0b75b09a5e6c86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
